{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5583dd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FASE 4: HYPERPARAMETER TUNING & MODEL OPTIMIZATION\n",
      "================================================================================\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# CELL 1: IMPORT LIBRARIES\n",
    "#==============================================================================\n",
    "\"\"\"\n",
    "Import semua libraries yang dibutuhkan untuk hyperparameter tuning.\n",
    "\"\"\"\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV, \n",
    "    cross_val_score, \n",
    "    StratifiedKFold,\n",
    "    cross_validate\n",
    ")\n",
    "\n",
    "# Imbalanced learning\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, auc,\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    cohen_kappa_score, matthews_corrcoef,\n",
    "    balanced_accuracy_score, make_scorer\n",
    ")\n",
    "\n",
    "# Statistical testing\n",
    "from scipy import stats\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 4: HYPERPARAMETER TUNING & MODEL OPTIMIZATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e569ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìÇ LOADING DATA & BASELINE MODEL\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Data Loaded:\n",
      "  ‚Ä¢ Training samples: 1508\n",
      "  ‚Ä¢ Test samples: 377\n",
      "  ‚Ä¢ Features: 24\n",
      "  ‚Ä¢ Feature names: ['Age_Encoded', 'Gender_Encoded', 'Education_Encoded', 'country_Australia', 'country_Canada', 'country_New Zealand', 'country_Other', 'country_Republic of Ireland', 'country_UK', 'country_USA', 'ethnicity_Asian', 'ethnicity_Black', 'ethnicity_Mixed-Black/Asian', 'ethnicity_Mixed-White/Asian', 'ethnicity_Mixed-White/Black', 'ethnicity_Other', 'ethnicity_White', 'Nscore', 'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS']\n",
      "\n",
      "‚úÖ Class Distribution:\n",
      "  ‚Ä¢ Training: Class 0=568, Class 1=940 (ratio: 0.60)\n",
      "  ‚Ä¢ Test: Class 0=142, Class 1=235 (ratio: 0.60)\n",
      "\n",
      "‚úÖ Baseline Model Performance (Recap):\n",
      "  ‚Ä¢ Test Accuracy: 0.8647\n",
      "  ‚Ä¢ Test ROC-AUC: 0.9271\n",
      "  ‚Ä¢ Test F1-Score: 0.8898\n",
      "  ‚Ä¢ Training Time: 0.47s\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# CELL 2: LOAD DATA & BASELINE MODEL\n",
    "#==============================================================================\n",
    "\"\"\"\n",
    "Load preprocessed data dan baseline model untuk comparison.\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÇ LOADING DATA & BASELINE MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load training data\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
    "\n",
    "# Load test data\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').values.ravel()\n",
    "\n",
    "# Load baseline model\n",
    "baseline_model = joblib.load('../models/baseline_rf_model.pkl')\n",
    "\n",
    "# Load baseline metrics\n",
    "with open('../results/metrics/03_baseline_metrics.json', 'r') as f:\n",
    "    baseline_metrics = json.load(f)\n",
    "\n",
    "print(\"\\n‚úÖ Data Loaded:\")\n",
    "print(f\"  ‚Ä¢ Training samples: {len(X_train)}\")\n",
    "print(f\"  ‚Ä¢ Test samples: {len(X_test)}\")\n",
    "print(f\"  ‚Ä¢ Features: {X_train.shape[1]}\")\n",
    "print(f\"  ‚Ä¢ Feature names: {X_train.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n‚úÖ Class Distribution:\")\n",
    "train_dist = Counter(y_train)\n",
    "test_dist = Counter(y_test)\n",
    "print(f\"  ‚Ä¢ Training: Class 0={train_dist[0]}, Class 1={train_dist[1]} (ratio: {train_dist[0]/train_dist[1]:.2f})\")\n",
    "print(f\"  ‚Ä¢ Test: Class 0={test_dist[0]}, Class 1={test_dist[1]} (ratio: {test_dist[0]/test_dist[1]:.2f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Baseline Model Performance (Recap):\")\n",
    "print(f\"  ‚Ä¢ Test Accuracy: {baseline_metrics['test_metrics']['accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Test ROC-AUC: {baseline_metrics['test_metrics']['roc_auc']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Test F1-Score: {baseline_metrics['test_metrics']['f1_score']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Training Time: {baseline_metrics['model_info']['training_time_seconds']:.2f}s\")\n",
    "\n",
    "# Get baseline predictions for later comparison\n",
    "y_test_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ef8bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîß DEFINING HYPERPARAMETER SEARCH SPACE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Search Space Defined:\n",
      "  ‚Ä¢ n_estimators        : [100, 200, 300, 500, 1000]\n",
      "  ‚Ä¢ max_depth           : [10, 20, 30, 40, None]\n",
      "  ‚Ä¢ min_samples_split   : [2, 5, 10, 20]\n",
      "  ‚Ä¢ min_samples_leaf    : [1, 2, 4, 8]\n",
      "  ‚Ä¢ max_features        : ['sqrt', 'log2', 0.3, 0.5]\n",
      "  ‚Ä¢ bootstrap           : [True, False]\n",
      "  ‚Ä¢ class_weight        : ['balanced', 'balanced_subsample', None]\n",
      "  ‚Ä¢ criterion           : ['gini', 'entropy']\n",
      "\n",
      "‚úÖ Total possible combinations: 19,200\n",
      "‚úÖ RandomizedSearchCV will sample: 100 combinations\n",
      "‚úÖ With 5-fold CV: 100 √ó 5 = 500 model fits\n",
      "‚úÖ Estimated time: 10-30 minutes (depending on hardware)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# CELL 3: DEFINE HYPERPARAMETER SEARCH SPACE\n",
    "#==============================================================================\n",
    "\"\"\"\n",
    "Define comprehensive hyperparameter search space untuk RandomizedSearchCV.\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîß DEFINING HYPERPARAMETER SEARCH SPACE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_distributions = {\n",
    "    # Number of trees\n",
    "    'n_estimators': [100, 200, 300, 500, 1000],\n",
    "    \n",
    "    # Tree depth (add constraint to reduce overfitting)\n",
    "    'max_depth': [10, 20, 30, 40, None],\n",
    "    \n",
    "    # Minimum samples to split a node (increase to reduce overfitting)\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    \n",
    "    # Minimum samples at leaf node\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    \n",
    "    # Number of features for best split\n",
    "    'max_features': ['sqrt', 'log2', 0.3, 0.5],\n",
    "    \n",
    "    # Bootstrap sampling\n",
    "    'bootstrap': [True, False],\n",
    "    \n",
    "    # Class weights (for handling imbalance)\n",
    "    'class_weight': ['balanced', 'balanced_subsample', None],\n",
    "    \n",
    "    # Split criterion\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Search Space Defined:\")\n",
    "for param, values in param_distributions.items():\n",
    "    print(f\"  ‚Ä¢ {param:20s}: {values}\")\n",
    "\n",
    "# Calculate total combinations\n",
    "total_combinations = 1\n",
    "for values in param_distributions.values():\n",
    "    total_combinations *= len(values)\n",
    "\n",
    "print(f\"\\n‚úÖ Total possible combinations: {total_combinations:,}\")\n",
    "print(f\"‚úÖ RandomizedSearchCV will sample: 100 combinations\")\n",
    "print(f\"‚úÖ With 5-fold CV: 100 √ó 5 = 500 model fits\")\n",
    "print(f\"‚úÖ Estimated time: 10-30 minutes (depending on hardware)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b494150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîç HYPERPARAMETER TUNING - RANDOMIZED SEARCH CV\n",
      "================================================================================\n",
      "\n",
      "‚öôÔ∏è  Setting up RandomizedSearchCV...\n",
      "\n",
      "‚úÖ RandomizedSearchCV Configuration:\n",
      "  ‚Ä¢ Estimator: RandomForestClassifier\n",
      "  ‚Ä¢ n_iter: 100 (sample 100 combinations)\n",
      "  ‚Ä¢ Scoring: roc_auc\n",
      "  ‚Ä¢ CV: 5-fold Stratified\n",
      "  ‚Ä¢ n_jobs: -1 (all cores)\n",
      "  ‚Ä¢ Total fits: 100 √ó 5 = 500\n",
      "\n",
      "üöÄ Starting hyperparameter search...\n",
      "‚è±Ô∏è  This will take 10-30 minutes depending on your hardware...\n",
      "--------------------------------------------------------------------------------\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      "================================================================================\n",
      "‚úÖ HYPERPARAMETER TUNING COMPLETED!\n",
      "‚è±Ô∏è  Total time: 5.03 minutes (302 seconds)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# CELL 4: RANDOMIZED SEARCH CV\n",
    "#==============================================================================\n",
    "\"\"\"\n",
    "Perform RandomizedSearchCV untuk find optimal hyperparameters.\n",
    "PALING LAMA: 10-30 menit tergantung hardware!\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç HYPERPARAMETER TUNING - RANDOMIZED SEARCH CV\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize base Random Forest\n",
    "rf_base = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "print(\"\\n‚öôÔ∏è  Setting up RandomizedSearchCV...\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,  # Sample 100 combinations\n",
    "    scoring='roc_auc',  # Optimize for ROC-AUC as per proposal\n",
    "    cv=cv_strategy,\n",
    "    verbose=2,  # Show progress\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # Parallel processing\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ RandomizedSearchCV Configuration:\")\n",
    "print(f\"  ‚Ä¢ Estimator: RandomForestClassifier\")\n",
    "print(f\"  ‚Ä¢ n_iter: 100 (sample 100 combinations)\")\n",
    "print(f\"  ‚Ä¢ Scoring: roc_auc\")\n",
    "print(f\"  ‚Ä¢ CV: 5-fold Stratified\")\n",
    "print(f\"  ‚Ä¢ n_jobs: -1 (all cores)\")\n",
    "print(f\"  ‚Ä¢ Total fits: 100 √ó 5 = 500\")\n",
    "\n",
    "# Perform hyperparameter search\n",
    "print(\"\\nüöÄ Starting hyperparameter search...\")\n",
    "print(\"‚è±Ô∏è  This will take 10-30 minutes depending on your hardware...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train, y_train)\n",
    "tuning_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ HYPERPARAMETER TUNING COMPLETED!\")\n",
    "print(f\"‚è±Ô∏è  Total time: {tuning_time/60:.2f} minutes ({tuning_time:.0f} seconds)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2ffc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèÜ BEST HYPERPARAMETERS FOUND\n",
      "================================================================================\n",
      "\n",
      "‚úÖ Best Parameters:\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ bootstrap           : True\n",
      "  ‚Ä¢ class_weight        : None\n",
      "  ‚Ä¢ criterion           : gini\n",
      "  ‚Ä¢ max_depth           : 20\n",
      "  ‚Ä¢ max_features        : log2\n",
      "  ‚Ä¢ min_samples_leaf    : 8\n",
      "  ‚Ä¢ min_samples_split   : 10\n",
      "  ‚Ä¢ n_estimators        : 500\n",
      "\n",
      "‚úÖ Best Cross-Validation Score:\n",
      "  ‚Ä¢ ROC-AUC: 0.8984\n",
      "\n",
      "‚úÖ Best Model Info:\n",
      "  ‚Ä¢ n_estimators: 500\n",
      "  ‚Ä¢ max_depth: 20\n",
      "  ‚Ä¢ min_samples_split: 10\n",
      "  ‚Ä¢ min_samples_leaf: 8\n",
      "  ‚Ä¢ max_features: log2\n",
      "  ‚Ä¢ criterion: gini\n",
      "  ‚Ä¢ bootstrap: True\n",
      "  ‚Ä¢ class_weight: None\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# CELL 5: BEST HYPERPARAMETERS\n",
    "#==============================================================================\n",
    "\"\"\"\n",
    "Extract dan display best hyperparameters found.\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ BEST HYPERPARAMETERS FOUND\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(\"\\n‚úÖ Best Parameters:\")\n",
    "print(\"-\"*80)\n",
    "for param, value in sorted(best_params.items()):\n",
    "    print(f\"  ‚Ä¢ {param:20s}: {value}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Best Cross-Validation Score:\")\n",
    "print(f\"  ‚Ä¢ ROC-AUC: {best_score:.4f}\")\n",
    "\n",
    "# Get best model\n",
    "best_rf_model = random_search.best_estimator_\n",
    "\n",
    "print(f\"\\n‚úÖ Best Model Info:\")\n",
    "print(f\"  ‚Ä¢ n_estimators: {best_rf_model.n_estimators}\")\n",
    "print(f\"  ‚Ä¢ max_depth: {best_rf_model.max_depth}\")\n",
    "print(f\"  ‚Ä¢ min_samples_split: {best_rf_model.min_samples_split}\")\n",
    "print(f\"  ‚Ä¢ min_samples_leaf: {best_rf_model.min_samples_leaf}\")\n",
    "print(f\"  ‚Ä¢ max_features: {best_rf_model.max_features}\")\n",
    "print(f\"  ‚Ä¢ criterion: {best_rf_model.criterion}\")\n",
    "print(f\"  ‚Ä¢ bootstrap: {best_rf_model.bootstrap}\")\n",
    "print(f\"  ‚Ä¢ class_weight: {best_rf_model.class_weight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70ebeff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä EVALUATING TUNED MODEL ON TEST SET\n",
      "================================================================================\n",
      "\n",
      "‚öôÔ∏è  Generating predictions...\n",
      "‚úÖ Predictions generated!\n",
      "\n",
      "‚úÖ TUNED MODEL PERFORMANCE:\n",
      "================================================================================\n",
      "          Accuracy  Precision  Recall  Specificity  F1-Score  Balanced Accuracy  ROC-AUC  PR-AUC  Cohen Kappa    MCC\n",
      "Set                                                                                                                 \n",
      "Training    0.8707     0.9045  0.8862       0.8451    0.8952             0.8656   0.9441  0.9680       0.7264 0.7267\n",
      "Test        0.8621     0.9031  0.8723       0.8451    0.8874             0.8587   0.9347  0.9612       0.7095 0.7102\n",
      "\n",
      "‚úÖ Confusion Matrix Breakdown:\n",
      "--------------------------------------------------------------------------------\n",
      "           TP   TN  FP   FN\n",
      "Set                        \n",
      "Training  833  480  88  107\n",
      "Test      205  120  22   30\n",
      "\n",
      "‚úÖ Overfitting Analysis:\n",
      "  ‚Ä¢ Training Accuracy: 0.8707\n",
      "  ‚Ä¢ Test Accuracy: 0.8621\n",
      "  ‚Ä¢ Gap: 0.0086 (0.86%)\n",
      "  ‚Ä¢ Status: ‚úÖ Good generalization (gap < 5%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#==============================================================================\n",
    "# CELL 6: EVALUATE TUNED MODEL ON TEST SET\n",
    "#==============================================================================\n",
    "\"\"\"\n",
    "Evaluate tuned model pada test set dengan comprehensive metrics.\n",
    "\"\"\"\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EVALUATING TUNED MODEL ON TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Predictions\n",
    "print(\"\\n‚öôÔ∏è  Generating predictions...\")\n",
    "y_train_pred_tuned = best_rf_model.predict(X_train)\n",
    "y_train_proba_tuned = best_rf_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "y_test_pred_tuned = best_rf_model.predict(X_test)\n",
    "y_test_proba_tuned = best_rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"‚úÖ Predictions generated!\")\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "def calculate_all_metrics(y_true, y_pred, y_pred_proba, set_name=\"\"):\n",
    "    \"\"\"Calculate all evaluation metrics\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    metrics = {\n",
    "        'Set': set_name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'Specificity': tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
    "        'F1-Score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'Balanced Accuracy': balanced_accuracy_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred_proba),\n",
    "        'PR-AUC': average_precision_score(y_true, y_pred_proba),\n",
    "        'Cohen Kappa': cohen_kappa_score(y_true, y_pred),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred),\n",
    "        'TP': int(tp),\n",
    "        'TN': int(tn),\n",
    "        'FP': int(fp),\n",
    "        'FN': int(fn)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics\n",
    "train_metrics_tuned = calculate_all_metrics(y_train, y_train_pred_tuned, \n",
    "                                            y_train_proba_tuned, \"Training\")\n",
    "test_metrics_tuned = calculate_all_metrics(y_test, y_test_pred_tuned, \n",
    "                                           y_test_proba_tuned, \"Test\")\n",
    "\n",
    "# Display results\n",
    "tuned_df = pd.DataFrame([train_metrics_tuned, test_metrics_tuned]).set_index('Set')\n",
    "\n",
    "print(\"\\n‚úÖ TUNED MODEL PERFORMANCE:\")\n",
    "print(\"=\"*80)\n",
    "display_cols = ['Accuracy', 'Precision', 'Recall', 'Specificity', 'F1-Score', \n",
    "                'Balanced Accuracy', 'ROC-AUC', 'PR-AUC', 'Cohen Kappa', 'MCC']\n",
    "print(tuned_df[display_cols].round(4).to_string())\n",
    "\n",
    "print(\"\\n‚úÖ Confusion Matrix Breakdown:\")\n",
    "print(\"-\"*80)\n",
    "cm_cols = ['TP', 'TN', 'FP', 'FN']\n",
    "print(tuned_df[cm_cols].to_string())\n",
    "\n",
    "# Check overfitting\n",
    "train_test_gap = train_metrics_tuned['Accuracy'] - test_metrics_tuned['Accuracy']\n",
    "print(f\"\\n‚úÖ Overfitting Analysis:\")\n",
    "print(f\"  ‚Ä¢ Training Accuracy: {train_metrics_tuned['Accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Test Accuracy: {test_metrics_tuned['Accuracy']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Gap: {train_test_gap:.4f} ({train_test_gap*100:.2f}%)\")\n",
    "\n",
    "if train_test_gap > 0.10:\n",
    "    print(\"  ‚Ä¢ Status: ‚ö†Ô∏è  Still some overfitting (gap > 10%)\")\n",
    "elif train_test_gap > 0.05:\n",
    "    print(\"  ‚Ä¢ Status: ‚ö†Ô∏è  Moderate overfitting (gap 5-10%)\")\n",
    "else:\n",
    "    print(\"  ‚Ä¢ Status: ‚úÖ Good generalization (gap < 5%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
